{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/pizza_request_dataset.json', 'r') as f:\n",
    "    requests = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.4 s, sys: 200 ms, total: 39.6 s\n",
      "Wall time: 39.9 s\n"
     ]
    }
   ],
   "source": [
    "%time request_text = [nlp(r['request_text_edit_aware']) for r in requests]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of words in a sentence to all ngrams\n",
    "def ngrams(words, n):\n",
    "    words = [w.strip().lower() for w in words]\n",
    "    return list(zip(*[words[i:] for i in range(n)]))\n",
    "\n",
    "# SpaCy sentence to words in sentence as strings\n",
    "def get_words(sentence):\n",
    "    return list(w.string for w in sentence if w.is_alpha)\n",
    "\n",
    "# Get all ngrams from a SpaCy corpus\n",
    "def get_request_ngrams(request, n):\n",
    "    return [gram for sent in request.sents for gram in ngrams(get_words(sent), n)]\n",
    "\n",
    "# Get all ngrams from a list of SpaCy corpora\n",
    "def get_all_ngrams(request_text, n):\n",
    "    grams = set()\n",
    "    for text in request_text:\n",
    "        grams.update(get_request_ngrams(text, n))\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 13295\n",
      "2: 110945\n",
      "3: 236221\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 2, 3]:\n",
    "    grams = get_all_ngrams(request_text, k)\n",
    "    print('{0}: {1}'.format(k, len(grams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538, ('pay', 'it', 'forward'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "doc_counts = defaultdict(int)\n",
    "\n",
    "for text in request_text:\n",
    "    request_trigrams = set(get_request_ngrams(text, 3))\n",
    "    for tri in request_trigrams:\n",
    "        doc_counts[tri] += 1\n",
    "        \n",
    "max((v, k) for k, v in doc_counts.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pizza modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_children_pos(token, pos):\n",
    "    return [t for t in token.children if t.pos_ == pos]\n",
    "\n",
    "pizza_mod_adj = defaultdict(int)\n",
    "pizza_mod_vb = defaultdict(int)\n",
    "\n",
    "for text in request_text:\n",
    "    for sent in text.sents:\n",
    "        for token in sent:\n",
    "            if 'pizza' in token.string.strip().lower():\n",
    "                for mod_token in get_children_pos(token, 'ADJ'):\n",
    "                    pizza_mod_adj[mod_token.string.strip().lower()] += 1\n",
    "                for mod_token in get_children_pos(token, 'VERB'):\n",
    "                    pizza_mod_vb[mod_token.lemma_] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'go'), (11, 'help'), (12, 'get'), (15, 'will'), (22, 'have'), (67, 'be')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((v, k) for k, v in pizza_mod_vb.items() if v > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'cheesy'),\n",
       " (11, 'little'),\n",
       " (11, 'simple'),\n",
       " (12, 'tasty'),\n",
       " (12, 'yummy'),\n",
       " (20, 'good'),\n",
       " (20, 'random'),\n",
       " (21, 'small'),\n",
       " (27, 'warm'),\n",
       " (30, 'large'),\n",
       " (30, 'my'),\n",
       " (45, 'hot'),\n",
       " (50, 'nice'),\n",
       " (52, 'delicious'),\n",
       " (65, 'free')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted((v, k) for k, v in pizza_mod_adj.items() if v > 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pizza = nlp('pizza')\n",
    "unigrams = get_all_ngrams(request_text, 1)\n",
    "sims = {w[0]: pizza.similarity(nlp(w[0])) for w in unigrams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sandwich     0.7160\n",
      "pizza        1.0000\n",
      "burger       0.7270\n",
      "burgers      0.7090\n",
      "pasta        0.7370\n",
      "sandwiches   0.7252\n"
     ]
    }
   ],
   "source": [
    "for word, sim in sims.items():\n",
    "    if sim > 0.7:\n",
    "        print('{0:<12} {1:.4f}'.format(word, sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def idf(request_text, n):\n",
    "    N = len(request_text)\n",
    "    nt = defaultdict(int)\n",
    "    for text in request_text:\n",
    "        for g in set(get_request_ngrams(text, n)):\n",
    "            nt[g] += 1\n",
    "    all_grams = get_all_ngrams(request_text, n)\n",
    "    return {g: np.log(float(N) / nt[g]) for g in all_grams}\n",
    "    \n",
    "unigram_idfs = idf(request_text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tf(text, n):\n",
    "    D = sum(len(s) for s in text.sents)\n",
    "    tfs = Counter(get_request_ngrams(text, n))\n",
    "    return {g: float(v) / D for g, v in tfs.items()}\n",
    "    \n",
    "unigram_tf = tf(request_text[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i',)          0.0144\n",
      "('not',)        0.0153\n",
      "('in',)         0.0094\n",
      "('college',)    0.0141\n",
      "('or',)         0.0186\n",
      "('a',)          0.0072\n",
      "('starving',)   0.0186\n",
      "('artist',)     0.0291\n",
      "('anything',)   0.0124\n",
      "('like',)       0.0186\n",
      "('that',)       0.0185\n",
      "('just',)       0.0118\n",
      "('been',)       0.0073\n",
      "('bit',)        0.0159\n",
      "('unlucky',)    0.0394\n",
      "('lately',)     0.0222\n",
      "('year',)       0.0148\n",
      "('old',)        0.0160\n",
      "('single',)     0.0226\n",
      "('guy',)        0.0202\n",
      "('with',)       0.0183\n",
      "('job',)        0.0104\n",
      "('but',)        0.0048\n",
      "('rent',)       0.0147\n",
      "('and',)        0.0047\n",
      "('other',)      0.0144\n",
      "('bills',)      0.0154\n",
      "('killed',)     0.0372\n",
      "('me',)         0.0145\n",
      "('this',)       0.0162\n",
      "('month',)      0.0134\n",
      "('thought',)    0.0172\n",
      "('had',)        0.0188\n",
      "('enough',)     0.0141\n",
      "('funds',)      0.0199\n",
      "('my',)         0.0044\n",
      "('account',)    0.0139\n",
      "('to',)         0.0060\n",
      "('at',)         0.0154\n",
      "('least',)      0.0195\n",
      "('keep',)       0.0178\n",
      "('set',)        0.0267\n",
      "('noodles',)    0.0211\n",
      "('forgot',)     0.0225\n",
      "('about',)      0.0209\n",
      "('monthly',)    0.0302\n",
      "('banking',)    0.0382\n",
      "('fee',)        0.0310\n",
      "('small',)      0.0196\n",
      "('bag',)        0.0269\n",
      "('of',)         0.0031\n",
      "('chips',)      0.0316\n",
      "('wednesday',)  0.0232\n",
      "('afternoon',)  0.0272\n",
      "('get',)        0.0126\n",
      "('paid',)       0.0116\n",
      "('monday',)     0.0188\n",
      "('so',)         0.0167\n",
      "('be',)         0.0142\n",
      "('fine',)       0.0237\n",
      "('then',)       0.0148\n",
      "('it',)         0.0112\n",
      "('really',)     0.0230\n",
      "('painful',)    0.0357\n",
      "('point',)      0.0205\n",
      "('food',)       0.0079\n",
      "('is',)         0.0048\n",
      "('something',)  0.0125\n",
      "('constantly',) 0.0304\n",
      "('thinking',)   0.0251\n",
      "('got',)        0.0109\n",
      "('few',)        0.0128\n",
      "('bucks',)      0.0245\n",
      "('on',)         0.0106\n",
      "('the',)        0.0023\n",
      "('bus',)        0.0268\n",
      "('work',)       0.0100\n",
      "('saturday',)   0.0240\n",
      "('ca',)         0.0127\n",
      "('use',)        0.0148\n",
      "('embarrassed',)0.0297\n",
      "('even',)       0.0131\n",
      "('asking',)     0.0178\n",
      "('sure',)       0.0150\n",
      "('how',)        0.0150\n",
      "('works',)      0.0193\n",
      "('please',)     0.0133\n",
      "('patient',)    0.0326\n",
      "('guess',)      0.0230\n",
      "('covers',)     0.0350\n",
      "('thank',)      0.0124\n",
      "('you',)        0.0065\n",
      "('advance',)    0.0184\n",
      "('cheers',)     0.0281\n",
      "('folks',)      0.0263\n"
     ]
    }
   ],
   "source": [
    "tf_idf = {w: unigram_tf[w] * unigram_idfs[w] for w in unigram_tf}\n",
    "for w, v in tf_idf.items():\n",
    "    print('{0:<16}{1:.4f}'.format(str(w), v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
